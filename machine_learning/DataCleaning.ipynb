{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataCleaning.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Y-k7l44Q-9-rSD7eCtSN_gWEZNxSn6kU","authorship_tag":"ABX9TyPVDYrKQD6VuAtO5Ea2Qcyg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"FCIibUIK0X5T"},"source":["!pip3 install dask\n","!pip install \"dask[complete]\" \n","!pip install tqdm\n","\n","import dask.dataframe as dd#similar to pandas\n","import datetime #Convert to unix time\n","\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import time #Convert to unix time\n","\n","# if numpy is not installed already : pip3 install numpy\n","import numpy as np#Do aritmetic operations on arrays\n","import math\n","import requests\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WC8ZW5qb0da2"},"source":["#The timestamps are converted to unix so as to get duration(trip-time) & speed also pickup-times in unix are used while binning \n","\n","# in out data we have time in the formate \"YYYY-MM-DD HH:MM:SS\" we convert thiss sting to python time formate and then into unix time stamp\n","# https://stackoverflow.com/a/27914405\n","def convert_to_unix(s):\n","    return time.mktime(datetime.datetime.fromisoformat(s).timetuple())\n","\n","\n","\n","# we return a data frame which contains the columns\n","# 1.'passenger_count' : self explanatory\n","# 2.'trip_distance' : self explanatory\n","# 3.'pickup_longitude' : self explanatory\n","# 4.'pickup_latitude' : self explanatory\n","# 5.'dropoff_longitude' : self explanatory\n","# 6.'dropoff_latitude' : self explanatory\n","# 7.'total_amount' : total fair that was paid\n","# 8.'trip_times' : duration of each trip\n","# 9.'pickup_times : pickup time converted into unix time \n","# 10.'Speed' : velocity of each trip\n","def return_with_trip_times(month):\n","    duration = month[['tpep_pickup_datetime','tpep_dropoff_datetime']].compute()\n","    #pickups and dropoffs to unix time\n","    duration_pickup = []\n","    duration_drop = []\n","    for pu, do in tqdm(zip(duration['tpep_pickup_datetime'].values, \\\n","                           duration['tpep_dropoff_datetime'].values)):\n","      duration_pickup.append(convert_to_unix(pu))\n","      duration_drop.append(convert_to_unix(do))\n","\n","    [convert_to_unix(x) for x in duration['tpep_pickup_datetime'].values]\n","    duration_drop = [convert_to_unix(x) for x in duration['tpep_dropoff_datetime'].values]\n","    #calculate duration of trips\n","    durations = (np.array(duration_drop) - np.array(duration_pickup))/float(60)\n","\n","    #append durations of trips and speed in miles/hr to a new dataframe\n","    new_frame = month[['passenger_count','trip_distance', 'pickup_longitude','pickup_latitude',\\\n","                       'dropoff_longitude','dropoff_latitude', 'total_amount']].compute()\n","    \n","    new_frame['trip_times'] = durations\n","    new_frame['pickup_times'] = duration_pickup\n","    new_frame['Speed'] = 60*(new_frame['trip_distance']/new_frame['trip_times'])\n","    \n","    return new_frame"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdaHt5jq0kwf"},"source":["#removing all outliers based on our univariate analysis above\n","def remove_outliers(new_frame):\n","\n","    \n","    a = new_frame.shape[0]\n","    print (\"Number of pickup records = \",a)\n","    temp_frame = new_frame\n","    temp_frame = new_frame[((new_frame.dropoff_longitude >= -74.15) & (new_frame.dropoff_longitude <= -73.7004) &\\\n","                       (new_frame.dropoff_latitude >= 40.5774) & (new_frame.dropoff_latitude <= 40.9176)) & \\\n","                       ((new_frame.pickup_longitude >= -74.15) & (new_frame.pickup_latitude >= 40.5774)& \\\n","                       (new_frame.pickup_longitude <= -73.7004) & (new_frame.pickup_latitude <= 40.9176))]\n","    b = temp_frame.shape[0]\n","    print (\"Number of outlier coordinates lying outside NY boundaries:\",(a-b))\n","\n","    \n","    temp_frame = new_frame[(new_frame.trip_times > 0) & (new_frame.trip_times < 720)]\n","    c = temp_frame.shape[0]\n","    print (\"Number of outliers from trip times analysis:\",(a-c))\n","    \n","    \n","    temp_frame = new_frame[(new_frame.trip_distance > 0) & (new_frame.trip_distance < 23)]\n","    d = temp_frame.shape[0]\n","    print (\"Number of outliers from trip distance analysis:\",(a-d))\n","    \n","    temp_frame = new_frame[(new_frame.Speed <= 65) & (new_frame.Speed >= 0)]\n","    e = temp_frame.shape[0]\n","    print (\"Number of outliers from speed analysis:\",(a-e))\n","    \n","    temp_frame = new_frame[(new_frame.total_amount <1000) & (new_frame.total_amount >0)]\n","    f = temp_frame.shape[0]\n","    print (\"Number of outliers from fare analysis:\",(a-f))\n","    \n","    \n","    new_frame = new_frame[((new_frame.dropoff_longitude >= -74.15) & (new_frame.dropoff_longitude <= -73.7004) &\\\n","                       (new_frame.dropoff_latitude >= 40.5774) & (new_frame.dropoff_latitude <= 40.9176)) & \\\n","                       ((new_frame.pickup_longitude >= -74.15) & (new_frame.pickup_latitude >= 40.5774)& \\\n","                       (new_frame.pickup_longitude <= -73.7004) & (new_frame.pickup_latitude <= 40.9176))]\n","    \n","    new_frame = new_frame[(new_frame.trip_times > 0) & (new_frame.trip_times < 720)]\n","    new_frame = new_frame[(new_frame.trip_distance > 0) & (new_frame.trip_distance < 23)]\n","    new_frame = new_frame[(new_frame.Speed < 45.31) & (new_frame.Speed > 0)]\n","    new_frame = new_frame[(new_frame.total_amount <1000) & (new_frame.total_amount >0)]\n","    \n","    print (\"Total outliers removed\",a - new_frame.shape[0])\n","    print (\"---\")\n","    return new_frame"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKrHs2BM0nEJ"},"source":["# we return a data frame which contains the columns\n","# 1.'pickup_longitude' : self explanatory\n","# 2.'pickup_latitude' : self explanatory\n","# 3.'pickup_times : pickup time converted into unix time \n","def clean(frame):\n","    print(\"Calculating durations...\")\n","    frame_with_durations = return_with_trip_times(frame)\n","    print (\"Removing outliers\")\n","    frame_with_durations_outliers_removed = remove_outliers(frame_with_durations)\n","    print(\"fraction of data points that remain after removing outliers\", float(len(frame_with_durations_outliers_removed))/len(frame_with_durations))\n","\n","    frame = frame_with_durations_outliers_removed[['pickup_longitude','pickup_latitude','pickup_times']]\n","    return frame"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UtUNWEV30oGY"},"source":["# returns the name of the csv file given year and month values\n","def get_name(year, month):\n","    assert year >= 2009 and year <= 2020, \"year should be in the range 2009-2020\"\n","    assert month >= 1 and month <= 12, \"month should be in the range 1-12\"\n","    if month < 10:\n","        month = \"0\" + str(month)\n","    name = \"yellow_tripdata_{}-{}.csv\".format(year, month)\n","    return name\n","\n","\n","# downloads NYC taxi data given year and month values\n","def download_data(year, month, dw_path=\"./data\"):\n","    name = get_name(year, month)\n","    save_path = os.path.join(dw_path, name)\n","    if not os.path.exists(save_path):\n","        print(\"Downloading {} ...\".format(name))\n","        url = \"https://s3.amazonaws.com/nyc-tlc/trip+data/\" + name\n","        os.system(\"wget -P {} {}\".format(dw_path, url))\n","        print(\"Download finished. File saved to {} ...\".format(save_path))\n","    else:\n","        print(name, \"already exists, skipping the download...\")\n","    return save_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nqo9_q4w0p4O"},"source":["# downloads NYC taxi data, cleans, and saves it given year and month values\n","def download_clean_save(year, month, save_dir=\"./clean\"):\n","    file_name = \"clean_\" + get_name(year, month)\n","    save_path = os.path.join(save_dir, file_name)\n","    if os.path.exists(save_path):\n","      print(file_name, \"already exists, skipping cleaning...\".format(file_name))\n","      return save_path\n","    file_path = download_data(year, month)\n","    frame = dd.read_csv(file_path, error_bad_lines=False, assume_missing=True)\n","    clean_frame = clean(frame)\n","    if \"Unnamed: 0\" in clean_frame.columns:\n","        clean_frame = clean_frame.drop(\"Unnamed: 0\", axis=1)\n","    clean_frame.to_csv(save_path, index=False)\n","    del clean_frame\n","    # delete the original file\n","    os.system(\"rm {}\".format(file_path))\n","    return save_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qQEFKqJ47mu"},"source":["year = 2016\n","month = 2\n","save_dir = \"/content/gdrive/MyDrive/New_York_Data/clean/\"\n","download_clean_save(year, month, save_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"id":"INFUzmEz0r-z","executionInfo":{"status":"ok","timestamp":1634312297337,"user_tz":-240,"elapsed":1667,"user":{"displayName":"AI Vengers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06452332470317445956"}},"outputId":"152245c8-e566-4616-bf3f-9b2c0f61248b"},"source":["path = download_data(2020, 1)\n","df = dd.read_csv(path, assume_missing=True)\n","print(df.columns)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["yellow_tripdata_2020-01.csv already exists, skipping...\n","Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n","       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n","       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n","       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n","       'total_amount', 'congestion_surcharge'],\n","      dtype='object')\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>VendorID</th>\n","      <th>tpep_pickup_datetime</th>\n","      <th>tpep_dropoff_datetime</th>\n","      <th>passenger_count</th>\n","      <th>trip_distance</th>\n","      <th>RatecodeID</th>\n","      <th>store_and_fwd_flag</th>\n","      <th>PULocationID</th>\n","      <th>DOLocationID</th>\n","      <th>payment_type</th>\n","      <th>fare_amount</th>\n","      <th>extra</th>\n","      <th>mta_tax</th>\n","      <th>tip_amount</th>\n","      <th>tolls_amount</th>\n","      <th>improvement_surcharge</th>\n","      <th>total_amount</th>\n","      <th>congestion_surcharge</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>2020-01-01 00:28:15</td>\n","      <td>2020-01-01 00:33:03</td>\n","      <td>1.0</td>\n","      <td>1.2</td>\n","      <td>1.0</td>\n","      <td>N</td>\n","      <td>238.0</td>\n","      <td>239.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>0.5</td>\n","      <td>1.47</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>11.27</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>2020-01-01 00:35:39</td>\n","      <td>2020-01-01 00:43:04</td>\n","      <td>1.0</td>\n","      <td>1.2</td>\n","      <td>1.0</td>\n","      <td>N</td>\n","      <td>239.0</td>\n","      <td>238.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>0.5</td>\n","      <td>1.50</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>12.30</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>2020-01-01 00:47:41</td>\n","      <td>2020-01-01 00:53:52</td>\n","      <td>1.0</td>\n","      <td>0.6</td>\n","      <td>1.0</td>\n","      <td>N</td>\n","      <td>238.0</td>\n","      <td>238.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>0.5</td>\n","      <td>1.00</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>10.80</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>2020-01-01 00:55:23</td>\n","      <td>2020-01-01 01:00:14</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>N</td>\n","      <td>238.0</td>\n","      <td>151.0</td>\n","      <td>1.0</td>\n","      <td>5.5</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>1.36</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>8.16</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>2020-01-01 00:01:58</td>\n","      <td>2020-01-01 00:04:16</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>N</td>\n","      <td>193.0</td>\n","      <td>193.0</td>\n","      <td>2.0</td>\n","      <td>3.5</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>4.80</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   VendorID tpep_pickup_datetime  ... total_amount  congestion_surcharge\n","0       1.0  2020-01-01 00:28:15  ...        11.27                   2.5\n","1       1.0  2020-01-01 00:35:39  ...        12.30                   2.5\n","2       1.0  2020-01-01 00:47:41  ...        10.80                   2.5\n","3       1.0  2020-01-01 00:55:23  ...         8.16                   0.0\n","4       2.0  2020-01-01 00:01:58  ...         4.80                   0.0\n","\n","[5 rows x 18 columns]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"IJ5s8KWP1jqt"},"source":["!cp /content/data/yellow_tripdata_2020-01.csv /content/drive/MyDrive/New_York_Data/clean/yellow_tripdata_2020-01.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sGiX0_Yzvjls"},"source":["# Daily"]},{"cell_type":"code","metadata":{"id":"swlv5aCfyTJD"},"source":["from collections import OrderedDict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WFcRLd5VxD7B"},"source":["def unix2datetime(unix):\n","  return datetime.datetime.utcfromtimestamp(int(unix))\n","\n","def print_unix(unix):\n","  print(unix2datetime(unix).strftime('%Y-%m-%d %H:%M:%S'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smgvDKSH7iwg"},"source":["# calculates weekdays for each entry in the data\n","def get_weekdays_list(df):\n","  weekdays = []\n","  print(\"Getting weekdays list...\")\n","  for t in tqdm(df['pickup_times'].values):\n","    weekdays.append(unix2datetime(t).weekday())\n","  return weekdays\n","\n","# saves data for each weekday separately\n","def save_weekdays(year, month, dir=\"/content/drive/MyDrive/New_York_Data/clean\"):\n","  full_name = \"clean_\" + get_name(year, month)\n","  path = os.path.join(dir, full_name)\n","  df = pd.read_csv(path)\n","  weekdays = get_weekdays_list(df)\n","  df['weekday'] = weekdays\n","\n","  # save each weekday separately\n","  name, ext = os.path.splitext(full_name)\n","  print(\"Saving each weekday separately...\")\n","  for i in tqdm(range(7)):\n","    new_name = name + \"_\" + str(i) + ext\n","    new_path = os.path.join(dir, new_name)\n","    if os.path.exists(new_path):\n","      print(\"{} already exists, skipping...\".format(new_path))\n","      continue\n","    day = df[df['weekday'] == i].drop(\"weekday\", axis=1)\n","    name, ext = os.path.splitext(full_name)\n","    new_name = name + \"_\" + str(i) + ext\n","    new_path = os.path.join(dir, new_name)\n","    day.to_csv(new_path, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8JcG_jR8x3X","executionInfo":{"status":"ok","timestamp":1634318194987,"user_tz":-240,"elapsed":81692,"user":{"displayName":"AI Vengers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06452332470317445956"}},"outputId":"a5c9b2e5-b527-417f-f914-73a4fdbf33d2"},"source":["save_weekdays(2016, 1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting weekdays list...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10609074/10609074 [00:10<00:00, 970123.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving each weekday separately...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7/7 [01:02<00:00,  8.87s/it]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"cEtEFQUhoWcD","executionInfo":{"status":"ok","timestamp":1634316994164,"user_tz":-240,"elapsed":6054,"user":{"displayName":"AI Vengers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06452332470317445956"}},"outputId":"05a596d9-5ffc-44e9-f7ec-9abd16d7e367"},"source":["dir = \"/content/drive/MyDrive/New_York_Data/clean\"\n","full_name = \"clean_yellow_tripdata_2016-01.csv\"\n","path = os.path.join(dir, full_name)\n","df = pd.read_csv(path)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>pickup_times</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-73.980118</td>\n","      <td>40.743050</td>\n","      <td>1.451606e+09</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-73.994057</td>\n","      <td>40.719990</td>\n","      <td>1.451606e+09</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-73.979424</td>\n","      <td>40.744614</td>\n","      <td>1.451606e+09</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-73.947151</td>\n","      <td>40.791046</td>\n","      <td>1.451606e+09</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-73.998344</td>\n","      <td>40.723896</td>\n","      <td>1.451606e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   pickup_longitude  pickup_latitude  pickup_times\n","0        -73.980118        40.743050  1.451606e+09\n","1        -73.994057        40.719990  1.451606e+09\n","2        -73.979424        40.744614  1.451606e+09\n","3        -73.947151        40.791046  1.451606e+09\n","4        -73.998344        40.723896  1.451606e+09"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"HigT7GpKEf-p"},"source":["save_dir = \"/content/drive/MyDrive/New_York_Data/clean\"\n","def download_clean_save_weekday(year, month):\n","  save_path = download_clean_save(year, month, save_dir=save_dir)\n","  save_weekdays(year, month, dir=save_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvZsKBTbGagm","executionInfo":{"status":"ok","timestamp":1634329910909,"user_tz":-240,"elapsed":132958,"user":{"displayName":"AI Vengers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06452332470317445956"}},"outputId":"0ace964f-4096-435f-da8a-3cf02d33098e"},"source":["for i in range(9, 12):\n","  try:\n","    download_clean_save_weekday(2016, i)\n","  except Exception as e:\n","    print(\"Problem with month\", i, \":\", e)\n","    continue"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["yellow_tripdata_2016-09.csv already exists, skipping the download...\n","Calculating durations...\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Problem with month 9 : fromisoformat: argument must be str\n","Downloading yellow_tripdata_2016-10.csv ...\n","Download finished. File saved to ./data/yellow_tripdata_2016-10.csv ...\n","Calculating durations...\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Problem with month 10 : fromisoformat: argument must be str\n","Downloading yellow_tripdata_2016-11.csv ...\n","Download finished. File saved to ./data/yellow_tripdata_2016-11.csv ...\n","Calculating durations...\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Problem with month 11 : fromisoformat: argument must be str\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"pkJciozaaqfI"},"source":["df = pd.read_csv(\"/content/data/yellow_tripdata_2016-01.csv\", error_bad_lines=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"RLswrMqIk456","executionInfo":{"status":"ok","timestamp":1634329113512,"user_tz":-240,"elapsed":349,"user":{"displayName":"AI Vengers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06452332470317445956"}},"outputId":"7f3b727f-a379-4798-8542-0e97ed1342af"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>VendorID</th>\n","      <th>tpep_pickup_datetime</th>\n","      <th>tpep_dropoff_datetime</th>\n","      <th>passenger_count</th>\n","      <th>trip_distance</th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>RatecodeID</th>\n","      <th>store_and_fwd_flag</th>\n","      <th>dropoff_longitude</th>\n","      <th>dropoff_latitude</th>\n","      <th>payment_type</th>\n","      <th>fare_amount</th>\n","      <th>extra</th>\n","      <th>mta_tax</th>\n","      <th>tip_amount</th>\n","      <th>tolls_amount</th>\n","      <th>improvement_surcharge</th>\n","      <th>total_amount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>2</td>\n","      <td>1.10</td>\n","      <td>-73.990372</td>\n","      <td>40.734695</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>-73.981842</td>\n","      <td>40.732407</td>\n","      <td>2</td>\n","      <td>7.5</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>8.8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>5</td>\n","      <td>4.90</td>\n","      <td>-73.980782</td>\n","      <td>40.729912</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>-73.944473</td>\n","      <td>40.716679</td>\n","      <td>1</td>\n","      <td>18.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>19.3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>1</td>\n","      <td>10.54</td>\n","      <td>-73.984550</td>\n","      <td>40.679565</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>-73.950272</td>\n","      <td>40.788925</td>\n","      <td>1</td>\n","      <td>33.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>34.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>1</td>\n","      <td>4.75</td>\n","      <td>-73.993469</td>\n","      <td>40.718990</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>-73.962242</td>\n","      <td>40.657333</td>\n","      <td>2</td>\n","      <td>16.5</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>17.3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>2016-01-01 00:00:00</td>\n","      <td>3</td>\n","      <td>1.76</td>\n","      <td>-73.960625</td>\n","      <td>40.781330</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>-73.977264</td>\n","      <td>40.758514</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>8.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   VendorID tpep_pickup_datetime  ... improvement_surcharge  total_amount\n","0         2  2016-01-01 00:00:00  ...                   0.3           8.8\n","1         2  2016-01-01 00:00:00  ...                   0.3          19.3\n","2         2  2016-01-01 00:00:00  ...                   0.3          34.3\n","3         2  2016-01-01 00:00:00  ...                   0.3          17.3\n","4         2  2016-01-01 00:00:00  ...                   0.3           8.8\n","\n","[5 rows x 19 columns]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"Z6NsG-b0lA6k"},"source":["del df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0pZTMVqqk7i"},"source":[""],"execution_count":null,"outputs":[]}]}