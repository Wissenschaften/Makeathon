{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCIibUIK0X5T"
      },
      "outputs": [],
      "source": [
        "!pip3 install dask\n",
        "!pip install \"dask[complete]\" \n",
        "!pip install tqdm\n",
        "\n",
        "import dask.dataframe as dd#similar to pandas\n",
        "import datetime #Convert to unix time\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time #Convert to unix time\n",
        "\n",
        "# if numpy is not installed already : pip3 install numpy\n",
        "import numpy as np#Do aritmetic operations on arrays\n",
        "import math\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC8ZW5qb0da2"
      },
      "outputs": [],
      "source": [
        "# The following lines of code are inspired from https://github.com/Swetadas-1718/Taxi_demand_prediction/blob/main/New%20York%20Taxi%20demand%20forecasting%20.ipynb\n",
        "\n",
        "\n",
        "#The timestamps are converted to unix so as to get duration(trip-time) & speed also pickup-times in unix are used while binning \n",
        "\n",
        "# in out data we have time in the formate \"YYYY-MM-DD HH:MM:SS\" we convert thiss sting to python time formate and then into unix time stamp\n",
        "# https://stackoverflow.com/a/27914405\n",
        "def convert_to_unix(s):\n",
        "    return time.mktime(datetime.datetime.fromisoformat(s).timetuple())\n",
        "\n",
        "\n",
        "\n",
        "# we return a data frame which contains the columns\n",
        "# 1.'passenger_count' : self explanatory\n",
        "# 2.'trip_distance' : self explanatory\n",
        "# 3.'pickup_longitude' : self explanatory\n",
        "# 4.'pickup_latitude' : self explanatory\n",
        "# 5.'dropoff_longitude' : self explanatory\n",
        "# 6.'dropoff_latitude' : self explanatory\n",
        "# 7.'total_amount' : total fair that was paid\n",
        "# 8.'trip_times' : duration of each trip\n",
        "# 9.'pickup_times : pickup time converted into unix time \n",
        "# 10.'Speed' : velocity of each trip\n",
        "def return_with_trip_times(month):\n",
        "    duration = month[['tpep_pickup_datetime','tpep_dropoff_datetime']].compute()\n",
        "    #pickups and dropoffs to unix time\n",
        "    duration_pickup = []\n",
        "    duration_drop = []\n",
        "    for pu, do in tqdm(zip(duration['tpep_pickup_datetime'].values, \\\n",
        "                           duration['tpep_dropoff_datetime'].values)):\n",
        "      duration_pickup.append(convert_to_unix(pu))\n",
        "      duration_drop.append(convert_to_unix(do))\n",
        "\n",
        "    [convert_to_unix(x) for x in duration['tpep_pickup_datetime'].values]\n",
        "    duration_drop = [convert_to_unix(x) for x in duration['tpep_dropoff_datetime'].values]\n",
        "    #calculate duration of trips\n",
        "    durations = (np.array(duration_drop) - np.array(duration_pickup))/float(60)\n",
        "\n",
        "    #append durations of trips and speed in miles/hr to a new dataframe\n",
        "    new_frame = month[['passenger_count','trip_distance', 'pickup_longitude','pickup_latitude',\\\n",
        "                       'dropoff_longitude','dropoff_latitude', 'total_amount']].compute()\n",
        "    \n",
        "    new_frame['trip_times'] = durations\n",
        "    new_frame['pickup_times'] = duration_pickup\n",
        "    new_frame['Speed'] = 60*(new_frame['trip_distance']/new_frame['trip_times'])\n",
        "    \n",
        "    return new_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdaHt5jq0kwf"
      },
      "outputs": [],
      "source": [
        "# The following lines of code are inspired from https://github.com/Swetadas-1718/Taxi_demand_prediction/blob/main/New%20York%20Taxi%20demand%20forecasting%20.ipynb\n",
        "\n",
        "#removing all outliers based on our univariate analysis above\n",
        "def remove_outliers(new_frame):\n",
        "\n",
        "    \n",
        "    a = new_frame.shape[0]\n",
        "    print (\"Number of pickup records = \",a)\n",
        "    temp_frame = new_frame\n",
        "    temp_frame = new_frame[((new_frame.dropoff_longitude >= -74.15) & (new_frame.dropoff_longitude <= -73.7004) &\\\n",
        "                       (new_frame.dropoff_latitude >= 40.5774) & (new_frame.dropoff_latitude <= 40.9176)) & \\\n",
        "                       ((new_frame.pickup_longitude >= -74.15) & (new_frame.pickup_latitude >= 40.5774)& \\\n",
        "                       (new_frame.pickup_longitude <= -73.7004) & (new_frame.pickup_latitude <= 40.9176))]\n",
        "    b = temp_frame.shape[0]\n",
        "    print (\"Number of outlier coordinates lying outside NY boundaries:\",(a-b))\n",
        "\n",
        "    \n",
        "    temp_frame = new_frame[(new_frame.trip_times > 0) & (new_frame.trip_times < 720)]\n",
        "    c = temp_frame.shape[0]\n",
        "    print (\"Number of outliers from trip times analysis:\",(a-c))\n",
        "    \n",
        "    \n",
        "    temp_frame = new_frame[(new_frame.trip_distance > 0) & (new_frame.trip_distance < 23)]\n",
        "    d = temp_frame.shape[0]\n",
        "    print (\"Number of outliers from trip distance analysis:\",(a-d))\n",
        "    \n",
        "    temp_frame = new_frame[(new_frame.Speed <= 65) & (new_frame.Speed >= 0)]\n",
        "    e = temp_frame.shape[0]\n",
        "    print (\"Number of outliers from speed analysis:\",(a-e))\n",
        "    \n",
        "    temp_frame = new_frame[(new_frame.total_amount <1000) & (new_frame.total_amount >0)]\n",
        "    f = temp_frame.shape[0]\n",
        "    print (\"Number of outliers from fare analysis:\",(a-f))\n",
        "    \n",
        "    \n",
        "    new_frame = new_frame[((new_frame.dropoff_longitude >= -74.15) & (new_frame.dropoff_longitude <= -73.7004) &\\\n",
        "                       (new_frame.dropoff_latitude >= 40.5774) & (new_frame.dropoff_latitude <= 40.9176)) & \\\n",
        "                       ((new_frame.pickup_longitude >= -74.15) & (new_frame.pickup_latitude >= 40.5774)& \\\n",
        "                       (new_frame.pickup_longitude <= -73.7004) & (new_frame.pickup_latitude <= 40.9176))]\n",
        "    \n",
        "    new_frame = new_frame[(new_frame.trip_times > 0) & (new_frame.trip_times < 720)]\n",
        "    new_frame = new_frame[(new_frame.trip_distance > 0) & (new_frame.trip_distance < 23)]\n",
        "    new_frame = new_frame[(new_frame.Speed < 45.31) & (new_frame.Speed > 0)]\n",
        "    new_frame = new_frame[(new_frame.total_amount <1000) & (new_frame.total_amount >0)]\n",
        "    \n",
        "    print (\"Total outliers removed\",a - new_frame.shape[0])\n",
        "    print (\"---\")\n",
        "    return new_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKrHs2BM0nEJ"
      },
      "outputs": [],
      "source": [
        "# we return a data frame which contains the columns\n",
        "# 1.'pickup_longitude' : self explanatory\n",
        "# 2.'pickup_latitude' : self explanatory\n",
        "# 3.'pickup_times : pickup time converted into unix time \n",
        "def clean(frame):\n",
        "    print(\"Calculating durations...\")\n",
        "    frame_with_durations = return_with_trip_times(frame)\n",
        "    print (\"Removing outliers\")\n",
        "    frame_with_durations_outliers_removed = remove_outliers(frame_with_durations)\n",
        "    print(\"fraction of data points that remain after removing outliers\", float(len(frame_with_durations_outliers_removed))/len(frame_with_durations))\n",
        "\n",
        "    frame = frame_with_durations_outliers_removed[['pickup_longitude','pickup_latitude','pickup_times']]\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtUNWEV30oGY"
      },
      "outputs": [],
      "source": [
        "# returns the name of the csv file given year and month values\n",
        "def get_name(year, month):\n",
        "    assert year >= 2009 and year <= 2020, \"year should be in the range 2009-2020\"\n",
        "    assert month >= 1 and month <= 12, \"month should be in the range 1-12\"\n",
        "    if month < 10:\n",
        "        month = \"0\" + str(month)\n",
        "    name = \"yellow_tripdata_{}-{}.csv\".format(year, month)\n",
        "    return name\n",
        "\n",
        "\n",
        "# downloads NYC taxi data given year and month values\n",
        "def download_data(year, month, dw_path=\"./data\"):\n",
        "    name = get_name(year, month)\n",
        "    save_path = os.path.join(dw_path, name)\n",
        "    if not os.path.exists(save_path):\n",
        "        print(\"Downloading {} ...\".format(name))\n",
        "        url = \"https://s3.amazonaws.com/nyc-tlc/trip+data/\" + name\n",
        "        os.system(\"wget -P {} {}\".format(dw_path, url))\n",
        "        print(\"Download finished. File saved to {} ...\".format(save_path))\n",
        "    else:\n",
        "        print(name, \"already exists, skipping the download...\")\n",
        "    return save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqo9_q4w0p4O"
      },
      "outputs": [],
      "source": [
        "# downloads NYC taxi data, cleans, and saves it given year and month values\n",
        "def download_clean_save(year, month, save_dir=\"./clean\"):\n",
        "    file_name = \"clean_\" + get_name(year, month)\n",
        "    save_path = os.path.join(save_dir, file_name)\n",
        "    if os.path.exists(save_path):\n",
        "      print(file_name, \"already exists, skipping cleaning...\".format(file_name))\n",
        "      return save_path\n",
        "    file_path = download_data(year, month)\n",
        "    frame = dd.read_csv(file_path, error_bad_lines=False, assume_missing=True)\n",
        "    clean_frame = clean(frame)\n",
        "    if \"Unnamed: 0\" in clean_frame.columns:\n",
        "        clean_frame = clean_frame.drop(\"Unnamed: 0\", axis=1)\n",
        "    clean_frame.to_csv(save_path, index=False)\n",
        "    del clean_frame\n",
        "    # delete the original file\n",
        "    os.system(\"rm {}\".format(file_path))\n",
        "    return save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qQEFKqJ47mu"
      },
      "outputs": [],
      "source": [
        "year = 2016\n",
        "month = 2\n",
        "save_dir = \"/content/gdrive/MyDrive/New_York_Data/clean/\"\n",
        "download_clean_save(year, month, save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "INFUzmEz0r-z",
        "outputId": "152245c8-e566-4616-bf3f-9b2c0f61248b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yellow_tripdata_2020-01.csv already exists, skipping...\n",
            "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
            "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
            "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
            "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
            "       'total_amount', 'congestion_surcharge'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>tpep_pickup_datetime</th>\n",
              "      <th>tpep_dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>PULocationID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>congestion_surcharge</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-01-01 00:28:15</td>\n",
              "      <td>2020-01-01 00:33:03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>238.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>11.27</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-01-01 00:35:39</td>\n",
              "      <td>2020-01-01 00:43:04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>239.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>12.30</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-01-01 00:47:41</td>\n",
              "      <td>2020-01-01 00:53:52</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>238.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10.80</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-01-01 00:55:23</td>\n",
              "      <td>2020-01-01 01:00:14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>238.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.16</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2020-01-01 00:01:58</td>\n",
              "      <td>2020-01-01 00:04:16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.80</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   VendorID tpep_pickup_datetime  ... total_amount  congestion_surcharge\n",
              "0       1.0  2020-01-01 00:28:15  ...        11.27                   2.5\n",
              "1       1.0  2020-01-01 00:35:39  ...        12.30                   2.5\n",
              "2       1.0  2020-01-01 00:47:41  ...        10.80                   2.5\n",
              "3       1.0  2020-01-01 00:55:23  ...         8.16                   0.0\n",
              "4       2.0  2020-01-01 00:01:58  ...         4.80                   0.0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = download_data(2020, 1)\n",
        "df = dd.read_csv(path, assume_missing=True)\n",
        "print(df.columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ5s8KWP1jqt"
      },
      "outputs": [],
      "source": [
        "!cp /content/data/yellow_tripdata_2020-01.csv /content/drive/MyDrive/New_York_Data/clean/yellow_tripdata_2020-01.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGiX0_Yzvjls"
      },
      "source": [
        "# Daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swlv5aCfyTJD"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFcRLd5VxD7B"
      },
      "outputs": [],
      "source": [
        "def unix2datetime(unix):\n",
        "  return datetime.datetime.utcfromtimestamp(int(unix))\n",
        "\n",
        "def print_unix(unix):\n",
        "  print(unix2datetime(unix).strftime('%Y-%m-%d %H:%M:%S'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smgvDKSH7iwg"
      },
      "outputs": [],
      "source": [
        "# calculates weekdays for each entry in the data\n",
        "def get_weekdays_list(df):\n",
        "  weekdays = []\n",
        "  print(\"Getting weekdays list...\")\n",
        "  for t in tqdm(df['pickup_times'].values):\n",
        "    weekdays.append(unix2datetime(t).weekday())\n",
        "  return weekdays\n",
        "\n",
        "# saves data for each weekday separately\n",
        "def save_weekdays(year, month, dir=\"/content/drive/MyDrive/New_York_Data/clean\"):\n",
        "  full_name = \"clean_\" + get_name(year, month)\n",
        "  path = os.path.join(dir, full_name)\n",
        "  df = pd.read_csv(path)\n",
        "  weekdays = get_weekdays_list(df)\n",
        "  df['weekday'] = weekdays\n",
        "\n",
        "  # save each weekday separately\n",
        "  name, ext = os.path.splitext(full_name)\n",
        "  print(\"Saving each weekday separately...\")\n",
        "  for i in tqdm(range(7)):\n",
        "    new_name = name + \"_\" + str(i) + ext\n",
        "    new_path = os.path.join(dir, new_name)\n",
        "    if os.path.exists(new_path):\n",
        "      print(\"{} already exists, skipping...\".format(new_path))\n",
        "      continue\n",
        "    day = df[df['weekday'] == i].drop(\"weekday\", axis=1)\n",
        "    name, ext = os.path.splitext(full_name)\n",
        "    new_name = name + \"_\" + str(i) + ext\n",
        "    new_path = os.path.join(dir, new_name)\n",
        "    day.to_csv(new_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8JcG_jR8x3X",
        "outputId": "a5c9b2e5-b527-417f-f914-73a4fdbf33d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting weekdays list...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10609074/10609074 [00:10<00:00, 970123.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving each weekday separately...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [01:02<00:00,  8.87s/it]\n"
          ]
        }
      ],
      "source": [
        "save_weekdays(2016, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cEtEFQUhoWcD",
        "outputId": "05a596d9-5ffc-44e9-f7ec-9abd16d7e367"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>pickup_times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-73.980118</td>\n",
              "      <td>40.743050</td>\n",
              "      <td>1.451606e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-73.994057</td>\n",
              "      <td>40.719990</td>\n",
              "      <td>1.451606e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-73.979424</td>\n",
              "      <td>40.744614</td>\n",
              "      <td>1.451606e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-73.947151</td>\n",
              "      <td>40.791046</td>\n",
              "      <td>1.451606e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-73.998344</td>\n",
              "      <td>40.723896</td>\n",
              "      <td>1.451606e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pickup_longitude  pickup_latitude  pickup_times\n",
              "0        -73.980118        40.743050  1.451606e+09\n",
              "1        -73.994057        40.719990  1.451606e+09\n",
              "2        -73.979424        40.744614  1.451606e+09\n",
              "3        -73.947151        40.791046  1.451606e+09\n",
              "4        -73.998344        40.723896  1.451606e+09"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir = \"/content/drive/MyDrive/New_York_Data/clean\"\n",
        "full_name = \"clean_yellow_tripdata_2016-01.csv\"\n",
        "path = os.path.join(dir, full_name)\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HigT7GpKEf-p"
      },
      "outputs": [],
      "source": [
        "save_dir = \"/content/drive/MyDrive/New_York_Data/clean\"\n",
        "def download_clean_save_weekday(year, month):\n",
        "  save_path = download_clean_save(year, month, save_dir=save_dir)\n",
        "  save_weekdays(year, month, dir=save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvZsKBTbGagm",
        "outputId": "0ace964f-4096-435f-da8a-3cf02d33098e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yellow_tripdata_2016-09.csv already exists, skipping the download...\n",
            "Calculating durations...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem with month 9 : fromisoformat: argument must be str\n",
            "Downloading yellow_tripdata_2016-10.csv ...\n",
            "Download finished. File saved to ./data/yellow_tripdata_2016-10.csv ...\n",
            "Calculating durations...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem with month 10 : fromisoformat: argument must be str\n",
            "Downloading yellow_tripdata_2016-11.csv ...\n",
            "Download finished. File saved to ./data/yellow_tripdata_2016-11.csv ...\n",
            "Calculating durations...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem with month 11 : fromisoformat: argument must be str\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(9, 12):\n",
        "  try:\n",
        "    download_clean_save_weekday(2016, i)\n",
        "  except Exception as e:\n",
        "    print(\"Problem with month\", i, \":\", e)\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkJciozaaqfI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/data/yellow_tripdata_2016-01.csv\", error_bad_lines=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "RLswrMqIk456",
        "outputId": "7f3b727f-a379-4798-8542-0e97ed1342af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>tpep_pickup_datetime</th>\n",
              "      <th>tpep_dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.10</td>\n",
              "      <td>-73.990372</td>\n",
              "      <td>40.734695</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.981842</td>\n",
              "      <td>40.732407</td>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>4.90</td>\n",
              "      <td>-73.980782</td>\n",
              "      <td>40.729912</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.944473</td>\n",
              "      <td>40.716679</td>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>19.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>10.54</td>\n",
              "      <td>-73.984550</td>\n",
              "      <td>40.679565</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.950272</td>\n",
              "      <td>40.788925</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>34.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>4.75</td>\n",
              "      <td>-73.993469</td>\n",
              "      <td>40.718990</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.962242</td>\n",
              "      <td>40.657333</td>\n",
              "      <td>2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>17.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>1.76</td>\n",
              "      <td>-73.960625</td>\n",
              "      <td>40.781330</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.977264</td>\n",
              "      <td>40.758514</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   VendorID tpep_pickup_datetime  ... improvement_surcharge  total_amount\n",
              "0         2  2016-01-01 00:00:00  ...                   0.3           8.8\n",
              "1         2  2016-01-01 00:00:00  ...                   0.3          19.3\n",
              "2         2  2016-01-01 00:00:00  ...                   0.3          34.3\n",
              "3         2  2016-01-01 00:00:00  ...                   0.3          17.3\n",
              "4         2  2016-01-01 00:00:00  ...                   0.3           8.8\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6NsG-b0lA6k"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0pZTMVqqk7i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DataCleaning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
